{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"final_analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+---------+------------------+------------------+--------+--------------------+------------+-----------+---------+-----------+\n",
      "|jira_ticket_id|      date|completed|num_slack_messages|         num_hours|engineer|  ticket_description|  initiative|new_revenue|repo_name|lines_added|\n",
      "+--------------+----------+---------+------------------+------------------+--------+--------------------+------------+-----------+---------+-----------+\n",
      "|             1|2023-03-31|     true|             276.0| 62.13453674316406|    Dale|Taurus both absen...|  Efficiency|  5295.6553|        G|         42|\n",
      "|            12|2023-12-30|     true|             436.0| 61.72333526611328|   Daisy|Toronto funereal ...|  Efficiency|  3425.6223|        Q|         73|\n",
      "|            13|2023-03-24|    false|             294.0|  97.2278060913086| Unknown|sizzle animism ed...|  Efficiency|   2806.764|        R|         22|\n",
      "|            22|2023-06-22|    false|             366.0| 45.48678970336914|    Josh|spitfire aorta ji...|New Customer|   9540.159|        K|         63|\n",
      "|            47|2023-02-02|    false|             148.0|39.095054626464844|    Dale|structure immersi...|     Support|   5668.918|        W|         35|\n",
      "+--------------+----------+---------+------------------+------------------+--------+--------------------+------------+-----------+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"../data/predicted_datav0.parquet\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions to be answered:\n",
    "- Q1: What is the longest Jira ticket description?\n",
    "- Q2: Which repo has the most lines of code added?\n",
    "- Q3: Provide the maximum number of Slack messages in any ticket for each engineer\n",
    "- Q4: Mean hours spent on a ticket in June 2023\n",
    "- Q5: Total lines of code contributed by completed tickets to the repo 'A'\n",
    "- Q6: Total new revenue per engineer per company initiative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Carmela sibling musicology patron gunpoint Canfield mammal Santayana Freddie Waterhouse estuary eligible Todd bashaw repellent Jovanovich integrity windbreak halide pestilential italic desiccate Hanoverian Riordan Lathrop connotative ratify Chattanooga phenol enjoinder chase breakdown alkaloid homology cleric consistent pickle rather Barney dogma crocodile liaison endometrial embroider methodology within marketeer cope patrol paycheck Nevins Spokane theorem Jorgensen Wilma transoceanic Mansfield arboretum attribution chemistry Woodbury Cottrell prosodic lox fallacious tachyon coprocessor Furman putdown Pickford goose ignition icosahedral chemic reconnaissance aggravate marinade furthest converge Apocrypha formula cocky landlocked Hopkins stamp Bennington injudicious bulletin spontaneous whalebone prolific scavenge aliphatic balsam offprint shepherdess underling Banbury Rebecca flush'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def longest_ticket_description(df: DataFrame) -> str:\n",
    "    description = df.orderBy(F.length(\"ticket_description\").desc()).select(\"ticket_description\").limit(1).collect()[0][0]\n",
    "    return description\n",
    "\n",
    "# Get the result\n",
    "result_q1 = longest_ticket_description(df)\n",
    "result_q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|repo_name|\n",
      "+---------+\n",
      "|        R|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def repo_with_most_lines(df: DataFrame) -> DataFrame:\n",
    "    return df.groupBy(\"repo_name\").agg(F.sum(\"lines_added\").alias(\"total_lines\")).orderBy(F.desc(\"total_lines\")).limit(1).select(\"repo_name\")\n",
    "\n",
    "# Get the result\n",
    "result_q2 = repo_with_most_lines(df)\n",
    "result_q2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|engineer|max_messages|\n",
      "+--------+------------+\n",
      "|    Alex|       500.0|\n",
      "|   Daisy|       500.0|\n",
      "|    Dale|       500.0|\n",
      "|    Josh|       500.0|\n",
      "|  Sandra|       500.0|\n",
      "| Unknown|       500.0|\n",
      "|    alex|       500.0|\n",
      "|   daisy|       500.0|\n",
      "|    dale|       500.0|\n",
      "|    josh|       500.0|\n",
      "|  sandra|       500.0|\n",
      "+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def max_slack_messages_per_engineer(df: DataFrame) -> DataFrame:\n",
    "    return df.groupBy(\"engineer\").agg(F.max(\"num_slack_messages\").alias(\"max_messages\")).orderBy(\"engineer\")\n",
    "\n",
    "# Get the result\n",
    "result_q3 = max_slack_messages_per_engineer(df)\n",
    "result_q3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       mean_hours|\n",
      "+-----------------+\n",
      "|50.20965416646661|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def mean_hours_june_2023(df: DataFrame) -> DataFrame:\n",
    "    return df.filter((F.year(\"date\") == 2023) & (F.month(\"date\") == 6)).agg(F.mean(\"num_hours\").alias(\"mean_hours\"))\n",
    "\n",
    "# Get the result\n",
    "result_q4 = mean_hours_june_2023(df)\n",
    "result_q4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|total_lines|\n",
      "+-----------+\n",
      "|      85208|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def total_lines_completed_repo_a(df: DataFrame) -> DataFrame:\n",
    "    return df.filter((F.col(\"completed\") == True) & (F.col(\"repo_name\") == \"A\")).agg(F.sum(\"lines_added\").alias(\"total_lines\"))\n",
    "\n",
    "# Get the result\n",
    "result_q5 = total_lines_completed_repo_a(df)\n",
    "result_q5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+--------------------+\n",
      "|engineer|  initiative|       total_revenue|\n",
      "+--------+------------+--------------------+\n",
      "|    Alex|  Efficiency|2.6966255779155493E7|\n",
      "|    Alex|New Customer| 2.647524867811036E7|\n",
      "|    Alex|     Support|2.5910800018243313E7|\n",
      "|   Daisy|  Efficiency| 2.681017515390265E7|\n",
      "|   Daisy|New Customer|2.6610312955403924E7|\n",
      "|   Daisy|     Support|2.6257335872519135E7|\n",
      "|    Dale|  Efficiency|  2.68572271843884E7|\n",
      "|    Dale|New Customer|2.6060978011313647E7|\n",
      "|    Dale|     Support|2.6448138232634544E7|\n",
      "|    Josh|  Efficiency| 2.611526335034299E7|\n",
      "|    Josh|New Customer|2.6681857968283057E7|\n",
      "|    Josh|     Support|2.6748859962927252E7|\n",
      "|  Sandra|  Efficiency|2.5834171813203394E7|\n",
      "|  Sandra|New Customer|2.7332515504475117E7|\n",
      "|  Sandra|     Support|2.6311226631829336E7|\n",
      "| Unknown|  Efficiency|2.7215193001622915E7|\n",
      "| Unknown|New Customer|2.6835177124576285E7|\n",
      "| Unknown|     Support| 2.723762447342052E7|\n",
      "|    alex|  Efficiency|  1341800.4322223663|\n",
      "|    alex|New Customer|   1499986.730430603|\n",
      "+--------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def total_revenue_per_engineer_initiative(df: DataFrame) -> DataFrame:\n",
    "    return df.groupBy(\"engineer\", \"initiative\").agg(F.sum(\"new_revenue\").alias(\"total_revenue\")).orderBy(\"engineer\", \"initiative\")\n",
    "\n",
    "# Get the result\n",
    "result_q6 = total_revenue_per_engineer_initiative(df)\n",
    "result_q6.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
